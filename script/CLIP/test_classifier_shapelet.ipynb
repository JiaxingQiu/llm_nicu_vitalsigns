{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Set R environment variables using the conda environment path\n",
    "# r_home = '/sfs/gpfs/tardis/home/jq2uw/llm_nicu_vitalsigns/clip_env/lib/R'\n",
    "# os.environ['R_HOME'] = r_home\n",
    "# os.environ['R_LIBS'] = f\"{r_home}/library\"\n",
    "# os.environ['R_LIBS_USER'] = os.path.expanduser('~/R/goolf/4.3')\n",
    "# os.environ['LD_LIBRARY_PATH'] = f\"{r_home}/lib:\" + os.environ.get('LD_LIBRARY_PATH', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 333\n",
      "using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "from data import *\n",
    "from config import *\n",
    "from classifer import *\n",
    "from classifier_shapelet import *\n",
    "from describer import *\n",
    "print(\"using device: \", device)\n",
    "random_state = 333\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for debugging\n",
    "# import importlib\n",
    "# import models\n",
    "# importlib.reload(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of patients with positive labels:\n",
      "VitalID\n",
      "1018    8\n",
      "5170    8\n",
      "1464    8\n",
      "2361    8\n",
      "2791    8\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=9)]: Using backend LokyBackend with 9 concurrent workers.\n",
      "[Parallel(n_jobs=9)]: Done  32 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=9)]: Done 5138 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=9)]: Done 63704 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=9)]: Done 65353 out of 65353 | elapsed:   12.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This infant will survive.  This infant has gestational age 24 weeks. Birth weight is 360 grams.  No Bradycardia events.   Very low amount of consecutive increases. \n",
      "\n",
      "Sample of patients with positive labels:\n",
      "TestID\n",
      "817     8\n",
      "1903    8\n",
      "801     8\n",
      "508     8\n",
      "2518    8\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=9)]: Using backend LokyBackend with 9 concurrent workers.\n",
      "[Parallel(n_jobs=9)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=9)]: Done 14318 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=9)]: Done 61182 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=9)]: Done 61570 out of 61570 | elapsed:    7.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This infant will survive.  This infant has gestational age 33 weeks. Birth weight is 2630 grams.  No Bradycardia events.  It shows high variability.  Low amount of consecutive increases. \n"
     ]
    }
   ],
   "source": [
    "# -----------------Train Data-----------------\n",
    "df = pd.read_excel('../../data/PAS Challenge HR Data.xlsx', engine=\"calamine\")\n",
    "df.columns = df.columns.astype(str)\n",
    "df_y = pd.read_excel('../../data/PAS Challenge Outcome Data.xlsx', engine=\"calamine\")[['VitalID', 'DiedNICU', 'DeathAge']]\n",
    "df_demo = pd.read_excel('../../data/PAS Challenge Demographic Data.xlsx', engine=\"calamine\")\n",
    "df_x = pd.read_excel('../../data/PAS Challenge Model Data.xlsx', engine=\"calamine\")\n",
    "df = df.merge(df_x[['VitalID', 'VitalTime', 'Age']], on=['VitalID', 'VitalTime'], how='left')\n",
    "df = label_death7d(df, df_y, id_col='VitalID')\n",
    "df = df.merge(df_demo, on='VitalID', how='left')\n",
    "df_desc = generate_descriptions_parallel(ts_df = df.loc[:, '1':'300'], id_df = df.loc[:, ['VitalID', 'VitalTime']])\n",
    "df = df.merge(df_desc, on=['VitalID', 'VitalTime'], how='left')\n",
    "df = text_gen_input_column(df, config_dict['text_config'])\n",
    "df['rowid'] = df.index.to_series() \n",
    "df_train = df\n",
    "\n",
    "# -----------------Test Data-----------------\n",
    "df_y_test = pd.read_excel('../../data/Test Data/Test Demographic Key.xlsx', sheet_name=0, engine=\"calamine\")\n",
    "df_test = pd.read_excel('../../data/Test Data/Test HR Data.xlsx', sheet_name=0, engine=\"calamine\") # test hr with description\n",
    "df_test.columns = df_test.columns.astype(str)\n",
    "df_test = label_death7d(df_test, df_y_test, id_col='TestID')\n",
    "df_demo_test = pd.read_excel('../../data/Test Data/Test Demographic Data.xlsx', sheet_name=0, engine=\"calamine\")\n",
    "df_test = df_test.merge(df_demo_test, on='TestID', how='left')\n",
    "df_test['rowid'] = df_test.index.to_series()\n",
    "df_test['VitalTime'] = df_test['Age']*24*60*60 # convert to second since birth\n",
    "df_test['VitalTime'] = df_test['VitalTime'].astype(int)\n",
    "rename_dict = {'TestID': 'VitalID'}\n",
    "df_test = df_test.rename(columns=rename_dict)\n",
    "\n",
    "df_desc_test = generate_descriptions_parallel(ts_df = df_test.loc[:, '1':'300'], id_df = df_test.loc[:, ['VitalID', 'VitalTime']])\n",
    "df_test = df_test.merge(df_desc_test, on=['VitalID', 'VitalTime'], how='left')\n",
    "df_test = text_gen_input_column(df_test, config_dict['text_config'])\n",
    "df_test_org = df_test[df.columns]\n",
    "df_test, df_leftout = train_test_split(df_test_org, test_size=0.5, stratify=df_test_org['cl_event'], random_state=random_state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 300)\n",
      "(100, 300)\n",
      "Number of positives in y_true_train: 50\n",
      "Number of positives in y_true_test: 50\n"
     ]
    }
   ],
   "source": [
    "txt_ls_org = ['This infant will die in 7 days. ', 'This infant will survive. ']\n",
    "y_col = 'cl_event'\n",
    "# # ---- downsample negative class(es) ----\n",
    "# # sample 5000 rows from df_test[df_test[y_col]==txt_ls_org[1]], without replacement\n",
    "# neg_sample_size = 1000\n",
    "# df_test_downsampled = df_test[df_test[y_col]==txt_ls_org[1]].sample(n=neg_sample_size, replace=False, random_state=random_state)\n",
    "# df_test = pd.concat([df_test[df_test[y_col]==txt_ls_org[0]], df_test_downsampled])\n",
    "# df_train_downsampled = df_train[df_train[y_col]==txt_ls_org[1]].sample(n=neg_sample_size, replace=False, random_state=random_state)\n",
    "# df_train = pd.concat([df_train[df_train[y_col]==txt_ls_org[0]], df_train_downsampled])\n",
    "\n",
    "# ---- for testing only ----\n",
    "# sample 50 rows from df_train[df_train[y_col]==txt_ls_org[1]], without replacement\n",
    "# sample 50 rows from df_train[df_train[y_col]==txt_ls_org[0]], without replacement\n",
    "df_test_neg = df_test[df_test[y_col]==txt_ls_org[1]].sample(n=50, replace=False, random_state=random_state)\n",
    "df_test_pos = df_test[df_test[y_col]==txt_ls_org[0]].sample(n=50, replace=False, random_state=random_state)\n",
    "df_test = pd.concat([df_test_neg, df_test_pos])\n",
    "df_train_neg = df_train[df_train[y_col]==txt_ls_org[1]].sample(n=50, replace=False, random_state=random_state)\n",
    "df_train_pos = df_train[df_train[y_col]==txt_ls_org[0]].sample(n=50, replace=False, random_state=random_state)\n",
    "df_train = pd.concat([df_train_neg, df_train_pos])\n",
    "\n",
    "\n",
    "# ---- augment + balance train data----\n",
    "target_event_rate = len(df_test[df_test[y_col]==txt_ls_org[0]])/len(df_test)\n",
    "max_size = int(target_event_rate*len(df_train))\n",
    "if config_dict['ts_aug']:\n",
    "    df_train = augment_balance_data(df_train, \n",
    "                                    txt_ls_org, \n",
    "                                    y_col, \n",
    "                                    config_dict, \n",
    "                                    pretrained_model_path='./pretrained/hr_vae_linear_medium.pth', \n",
    "                                    K=10,\n",
    "                                    max_size=max_size)\n",
    "\n",
    "\n",
    "# ---- block or not ----\n",
    "# important for generating labels for block target\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "if not config_dict['block_target']:\n",
    "    df_train['label'] = df_train.index.to_series()\n",
    "    df_test['label'] = df_test.index.to_series()\n",
    "else:\n",
    "    df_train['label'] = df_train['rowid'].astype(int)\n",
    "    df_test['label'] = df_test['rowid'].astype(int)\n",
    "\n",
    "def get_y_true_and_ts_df(df_new, txt_ls_org):\n",
    "    df_new_y = pd.get_dummies(df_new['cl_event'])\n",
    "    df_new_y = df_new_y[txt_ls_org]\n",
    "    y_true = torch.tensor(df_new_y.values)\n",
    "    ts_df = df_new.loc[:,'1':'300']\n",
    "    return y_true, ts_df\n",
    "\n",
    "\n",
    "# ---- prepare for binary classification evaluation ----\n",
    "y_true_train, ts_df_train = get_y_true_and_ts_df(df_train, txt_ls_org)     # create y_true_train and ts_df_train\n",
    "y_true_test, ts_df_test = get_y_true_and_ts_df(df_test, txt_ls_org)     # create y_true_test and ts_df_test\n",
    "print(ts_df_train.shape)\n",
    "print(ts_df_test.shape)\n",
    "\n",
    "\n",
    "y_true_train = y_true_train.float()\n",
    "y_true_test = y_true_test.float() \n",
    "train_loader = prepare_basedata(ts_df_train, y_true_train)\n",
    "test_loader = prepare_basedata(ts_df_test, y_true_test)\n",
    "\n",
    "# get number of positives in y_true_train\n",
    "pos_count = (y_true_train[:,0] == 1).sum().item()\n",
    "print(f\"Number of positives in y_true_train: {pos_count}\")\n",
    "\n",
    "# get number of positives in y_true_test\n",
    "pos_count = (y_true_test[:,0] == 1).sum().item()\n",
    "print(f\"Number of positives in y_true_test: {pos_count}\")\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.array(ts_df_train) # nobs x 300\n",
    "y_train = np.array(y_true_train[:,0])# nobs ,\n",
    "X_test = np.array(ts_df_test) # nobs x 300\n",
    "y_test = np.array(y_true_test[:,0])# nobs ,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shapelet models to predict clinical outcomes end2end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Initialize classifier\n",
    "# clf = ShapeletClassifier(\n",
    "#     min_length=15, # 0.5 minute worth of data points\n",
    "#     max_length=60, # 2 minute worth of data points\n",
    "#     n_shapelets=5\n",
    "# )\n",
    "\n",
    "# # Fit classifier\n",
    "# clf.fit(X_train, y_train) \n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# # Get performance metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# # Get learned shapelets\n",
    "# shapelets = clf.get_shapelets()\n",
    "\n",
    "# # Visualize shapelets\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_shapelets(shapelets, title=\"Discovered Shapelets\"):\n",
    "#     fig, axes = plt.subplots(len(shapelets), 1, figsize=(10, 2*len(shapelets)))\n",
    "#     for i, (shapelet, score) in enumerate(shapelets):\n",
    "#         axes[i].plot(shapelet)\n",
    "#         axes[i].set_title(f\"Shapelet {i+1}, Information Gain: {score:.4f}\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_shapelets(shapelets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting candidates...\n",
      "Evaluating 19100 shapelets in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding shapelets:  63%|██████▎   | 12087/19100 [03:10<01:49, 63.99it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = FastShapeletClassifier(\n",
    "    min_length=110,    # 1 minute\n",
    "    max_length=115,   # 10 minutes\n",
    "    n_shapelets=5,\n",
    "    n_jobs=4#\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Get performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Get learned shapelets\n",
    "shapelets = clf.get_shapelets()\n",
    "\n",
    "# Visualize shapelets\n",
    "\n",
    "def plot_shapelets(shapelets, title=\"Discovered Shapelets\"):\n",
    "    fig, axes = plt.subplots(len(shapelets), 1, figsize=(10, 2*len(shapelets)))\n",
    "    for i, (shapelet, score) in enumerate(shapelets):\n",
    "        axes[i].plot(shapelet)\n",
    "        axes[i].set_title(f\"Shapelet {i+1}, Information Gain: {score:.4f}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_shapelets(shapelets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
