{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyqiu/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from data import *\n",
    "from encoders import *\n",
    "from config import *\n",
    "from models import *\n",
    "print(\"using device: \", device)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load local data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ugly engineering here\n",
    "df = pd.read_csv('../../data/HR_events.csv')\n",
    "df_y = pd.read_excel('../../data/PAS Challenge Outcome Data.xlsx', engine=\"calamine\")\n",
    "df_y = df_y[['VitalID', 'Died']]\n",
    "df = df.merge(df_y, on='VitalID', how='left')\n",
    "df['text'] = df['Died'].apply(lambda x: 'This infant will die in 7 days. ' if x == 1 else 'This infant will survive. ')\n",
    "# df['text'] = df['text'] +' '+ df['event_description'].astype(str)\n",
    "df['label'] = df.index.to_series()\n",
    "# df_train, df_test = train_test_split(df, test_size=0.2)    \n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['text'])    \n",
    "# df_train['text'] = df_train['text'] +' '+ df_train['label'].astype(str)\n",
    "# df_test['text'] = df_test['text'] +' '+ df_test['label'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare datasets and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyqiu/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# text_encoder_name = 'dmis-lab/biobert-base-cased-v1.2'\n",
    "text_encoder_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "\n",
    "ts_f_train, tx_f_train, labels_train = get_features(df_train, text_encoder_name=text_encoder_name)\n",
    "train_dataloader = CLIPDataset(ts_f_train, tx_f_train, labels_train).dataloader(batch_size=128)\n",
    "\n",
    "ts_f_test, tx_f_test, labels_test = get_features(df_test, text_encoder_name=text_encoder_name)\n",
    "test_dataloader = CLIPDataset(ts_f_test, tx_f_test, labels_test).dataloader(batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CLIPModel                                1\n",
      "├─Sequential: 1-1                        --\n",
      "│    └─Linear: 2-1                       8,448\n",
      "│    └─LeakyReLU: 2-2                    --\n",
      "│    └─Linear: 2-3                       65,792\n",
      "│    └─LeakyReLU: 2-4                    --\n",
      "│    └─Linear: 2-5                       65,792\n",
      "│    └─LeakyReLU: 2-6                    --\n",
      "│    └─Linear: 2-7                       32,896\n",
      "├─Sequential: 1-2                        --\n",
      "│    └─Linear: 2-8                       196,864\n",
      "│    └─LeakyReLU: 2-9                    --\n",
      "│    └─Linear: 2-10                      131,584\n",
      "│    └─LeakyReLU: 2-11                   --\n",
      "│    └─Linear: 2-12                      131,328\n",
      "│    └─LeakyReLU: 2-13                   --\n",
      "│    └─Linear: 2-14                      65,792\n",
      "│    └─LeakyReLU: 2-15                   --\n",
      "│    └─Linear: 2-16                      32,896\n",
      "=================================================================\n",
      "Total params: 731,393\n",
      "Trainable params: 731,393\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "overwrite = True\n",
    "model_path = './results/clip_hr_death.pth' \n",
    "loss_path = './results/clip_hr_death_losses.pth'\n",
    "# Initialize model\n",
    "model = CLIPModel(\n",
    "        ts_dim=ts_f_train.shape[1],    # 32\n",
    "        text_dim=tx_f_train.shape[1],  # 768\n",
    "        projection_dim=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/10000 [00:00<1:53:32,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000]\n",
      "\tTraining Loss: 4.839318\n",
      "\tTesting Loss: 4.813427\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/10000 [00:01<1:57:13,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10000]\n",
      "\tTraining Loss: 4.802921\n",
      "\tTesting Loss: 4.813421\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/10000 [00:02<1:58:51,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/10000 [00:02<1:56:21,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/10000 [00:03<1:57:28,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/10000 [00:04<1:56:10,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/10000 [00:04<1:55:01,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813419\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/10000 [00:05<1:53:57,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/10000 [00:06<1:53:44,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/10000 [00:06<1:54:30,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/10000 [00:07<1:53:10,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813419\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/10000 [00:08<1:52:54,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/10000 [00:08<1:52:38,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/10000 [00:09<1:55:09,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/10000 [00:10<1:54:19,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/10000 [00:11<1:55:05,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/10000 [00:11<1:54:21,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/10000 [00:12<1:53:30,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/10000 [00:13<1:53:17,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/10000 [00:13<1:52:08,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/10000 [00:14<1:52:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/10000 [00:15<1:51:31,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 23/10000 [00:15<1:52:13,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/10000 [00:16<1:51:56,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/10000 [00:17<1:51:16,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/10000 [00:17<1:51:27,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/10000 [00:18<1:52:01,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/10000 [00:19<1:51:41,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813419\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 29/10000 [00:19<1:51:14,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/10000 [00:20<1:52:37,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813419\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 31/10000 [00:21<1:51:50,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/10000 [00:21<1:51:09,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/10000 [00:22<1:50:56,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/10000 [00:23<1:50:54,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 35/10000 [00:23<1:50:51,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36/10000 [00:24<1:50:29,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/10000 [00:25<1:50:34,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 38/10000 [00:25<1:50:27,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 39/10000 [00:26<1:51:23,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40/10000 [00:27<1:51:30,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41/10000 [00:27<1:50:58,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 42/10000 [00:28<1:51:18,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 43/10000 [00:29<1:50:48,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 44/10000 [00:29<1:51:52,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 45/10000 [00:30<1:51:21,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 46/10000 [00:31<1:51:09,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 47/10000 [00:31<1:50:59,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 48/10000 [00:32<1:50:26,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 49/10000 [00:33<1:51:50,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 50/10000 [00:33<1:51:17,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 51/10000 [00:34<1:50:15,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 52/10000 [00:35<1:51:33,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 53/10000 [00:35<1:51:29,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 54/10000 [00:36<1:52:12,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813419\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 55/10000 [00:37<1:51:32,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 56/10000 [00:37<1:50:53,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 57/10000 [00:38<1:51:51,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 58/10000 [00:39<1:50:52,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 59/10000 [00:39<1:52:38,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 60/10000 [00:40<1:53:32,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 61/10000 [00:41<1:55:03,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813419\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 62/10000 [00:42<1:55:53,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813419\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 63/10000 [00:42<1:55:14,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 64/10000 [00:43<1:55:46,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 65/10000 [00:44<1:53:58,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 66/10000 [00:44<1:52:47,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 67/10000 [00:45<1:52:26,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 68/10000 [00:46<1:52:05,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/10000]\n",
      "\tTraining Loss: 4.802918\n",
      "\tTesting Loss: 4.813420\n",
      "\tLearning Rate: 0.005000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 69/10000 [00:46<1:52:06,  1.48it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "if overwrite or not os.path.exists(model_path):\n",
    "    num_epochs = 10000\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "    train_losses, test_losses = train(model, \n",
    "                                    train_dataloader,\n",
    "                                    test_dataloader, \n",
    "                                    optimizer, \n",
    "                                    num_epochs, \n",
    "                                    device)\n",
    "    # save model and losses\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    torch.save({\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses }, loss_path)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    train_losses = torch.load(loss_path)['train_losses']\n",
    "    test_losses = torch.load(loss_path)['test_losses']\n",
    "\n",
    "    # plot losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(test_losses, label='Test Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prob(model, df_new, text_model_name):\n",
    "    ts_f, tx_f, labels = get_features(df_new, text_encoder_name = text_model_name)\n",
    "    dataloader = CLIPDataset(ts_f, tx_f, labels).dataloader(batch_size=1)\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for _, (ts_features, text_features, labels) in enumerate(dataloader):\n",
    "            ts_features = ts_features.to(device)\n",
    "            text_features = text_features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits, _, _ = model(ts_features, text_features)\n",
    "            prob = F.softmax(logits, dim=1)\n",
    "            probs.append(prob)\n",
    "    probs = torch.cat(probs, dim=0)\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_new = df_test\n",
    "df_new['text']= 'this infant will die in 7 days'\n",
    "\n",
    "get_prob(model, df_new, text_model_name=text_encoder_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
