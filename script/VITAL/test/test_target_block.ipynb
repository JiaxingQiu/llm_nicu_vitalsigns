{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# # Set R environment variables using the conda environment path\n",
    "# r_home = '/sfs/gpfs/tardis/home/jq2uw/llm_nicu_vitalsigns/clip_env/lib/R'\n",
    "# os.environ['R_HOME'] = r_home\n",
    "# os.environ['R_LIBS'] = f\"{r_home}/library\"\n",
    "# os.environ['R_LIBS_USER'] = os.path.expanduser('~/R/goolf/4.3')\n",
    "# os.environ['LD_LIBRARY_PATH'] = f\"{r_home}/lib:\" + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 333\n",
      "using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from data import *\n",
    "from train import *\n",
    "from eval import *\n",
    "from vital import *\n",
    "print(\"using device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (customize) configs\n",
    "overwrite = True\n",
    "model_name = 'test_succ_inc2'\n",
    "text_config['cl']['die7d'] = True # udpate text_config here if needed\n",
    "# model_name = model_name + \"___\" + \"_\".join(get_true_components(text_config))\n",
    "\n",
    "update_config(\n",
    "    text_col = 'description_succ_inc',#'ts_description',\n",
    "    y_col = 'description_succ_inc',\n",
    "    y_levels = ['High amount of consecutive increases.', 'Low amount of consecutive increases.'],\n",
    "    y_pred_levels = ['High amount of consecutive increases.', 'Low amount of consecutive increases.'],\n",
    "    txt2ts_y_cols = ['description_succ_inc'],\n",
    "    model_name = model_name,\n",
    "    downsample_levels =['High amount of consecutive increases.', 'Low amount of consecutive increases.'],\n",
    "    downsample = True,\n",
    "    downsample_size = 50,\n",
    "    custom_target_cols = ['description_succ_inc', 'label'], # 'label' is the same as the default \"by_label\" target\n",
    "    embedded_dim = 256,\n",
    "    batch_size = 512, # Data loader settings\n",
    "    patience = 100, # Training settings\n",
    "    num_saves = 10,\n",
    "    num_epochs = 10,\n",
    "    init_lr = 5e-5,\n",
    "    text_config = text_config,\n",
    "    **{'3d': False}  # Add this line\n",
    ")\n",
    "config_dict = get_config_dict()\n",
    "\n",
    "\n",
    "#  result saving directory\n",
    "output_dir = './results/'+config_dict['model_name']\n",
    "model_clip_path = output_dir+'/model_clip.pth' \n",
    "eval_clip_path = output_dir+'/evals_clip.pth'\n",
    "model_path = output_dir+'/model.pth' \n",
    "eval_path = output_dir+'/evals.pth'\n",
    "config_path = output_dir+'/config.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of patients with positive labels:\n",
      "VitalID\n",
      "1018    8\n",
      "5170    8\n",
      "1835    8\n",
      "2361    8\n",
      "2791    8\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=9)]: Using backend LokyBackend with 9 concurrent workers.\n",
      "[Parallel(n_jobs=9)]: Done  32 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=9)]: Done 2596 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=9)]: Done 63298 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=9)]: Done 65100 out of 65100 | elapsed:   12.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace 'text' with:  description_succ_inc\n",
      "text\n",
      "Moderate amount of consecutive increases.    42910\n",
      "Low amount of consecutive increases.         11838\n",
      "High amount of consecutive increases.        10352\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of patients with positive labels:\n",
      "TestID\n",
      "508     8\n",
      "707     8\n",
      "1903    8\n",
      "817     8\n",
      "1414    7\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=9)]: Using backend LokyBackend with 9 concurrent workers.\n",
      "[Parallel(n_jobs=9)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=9)]: Done 14318 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=9)]: Done 60894 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=9)]: Done 61197 out of 61197 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace 'text' with:  description_succ_inc\n",
      "text\n",
      "Moderate amount of consecutive increases.    36173\n",
      "Low amount of consecutive increases.         13165\n",
      "High amount of consecutive increases.        11859\n",
      "Name: count, dtype: int64\n",
      "After downsampling:\n",
      "description_succ_inc\n",
      "High amount of consecutive increases.    50\n",
      "Low amount of consecutive increases.     50\n",
      "Name: count, dtype: int64\n",
      "After downsampling:\n",
      "description_succ_inc\n",
      "High amount of consecutive increases.    50\n",
      "Low amount of consecutive increases.     50\n",
      "Name: count, dtype: int64\n",
      "final distribution of text prediction\n",
      "description_succ_inc\n",
      "High amount of consecutive increases.    50\n",
      "Low amount of consecutive increases.     50\n",
      "Name: count, dtype: int64\n",
      "description_succ_inc\n",
      "High amount of consecutive increases.    50\n",
      "Low amount of consecutive increases.     50\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTimeSeries/llm_nicu_vitalsigns/clip_env/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# run preprocess.py to ready the data\n",
    "with open('main_preprocess.py', 'r') as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.5000,  ..., 0.0000, 0.5000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.5000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.0000, 1.0000,  ..., 0.0000, 0.5000, 0.5000],\n",
      "        ...,\n",
      "        [0.0000, 0.5000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.0000, 0.5000,  ..., 0.0000, 1.0000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000,  ..., 0.0000, 0.5000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "for _, (idx, ts, text_features, labels, targets) in enumerate(train_dataloader):\n",
    "    targets = targets[:,idx]\n",
    "    print(targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gen_target(df, \n",
    "               cluster_cols):\n",
    "    targets = {}\n",
    "    for cluster_col in cluster_cols:\n",
    "        label_mapping = {cat: idx+1 for idx, cat in enumerate(sorted(df[cluster_col].unique()))}\n",
    "        df['cluster'] = df[cluster_col].map(label_mapping).astype(int)\n",
    "        labels = torch.tensor(df['cluster'].values)\n",
    "        labels_equal = (labels.unsqueeze(0) == labels.unsqueeze(1))\n",
    "        target = labels_equal.float()\n",
    "        targets[cluster_col] = target\n",
    "\n",
    "    # Sum all target matrices element-wise\n",
    "    target_sum = sum(targets.values())\n",
    "    # Method 2: Normalize by count\n",
    "    target_normalized = target_sum / len(cluster_cols)\n",
    "    return target_normalized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_cols = ['description_succ_inc', 'description_succ_unc', 'cl_event', 'rowid']\n",
    "df = df_train\n",
    "target = gen_target(df, cluster_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.7500, 0.7500,  ..., 0.7500, 0.7500, 0.2500],\n",
       "        [0.7500, 1.0000, 0.7500,  ..., 0.7500, 0.7500, 0.2500],\n",
       "        [0.7500, 0.7500, 1.0000,  ..., 0.7500, 0.7500, 0.2500],\n",
       "        ...,\n",
       "        [0.7500, 0.7500, 0.7500,  ..., 1.0000, 0.7500, 0.2500],\n",
       "        [0.7500, 0.7500, 0.7500,  ..., 0.7500, 1.0000, 0.2500],\n",
       "        [0.2500, 0.2500, 0.2500,  ..., 0.2500, 0.2500, 1.0000]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_col = cluster_cols[0]\n",
    "label_mapping = {cat: idx+1 for idx, cat in enumerate(sorted(df_train[cluster_col].unique()))}\n",
    "df_train['label'] = df_train[cluster_col].map(label_mapping).astype(int)\n",
    "df_test['label'] = df_test[cluster_col].map(label_mapping).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
