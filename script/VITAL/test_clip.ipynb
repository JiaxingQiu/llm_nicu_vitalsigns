{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Set R environment variables using the conda environment path\n",
    "# r_home = '/sfs/gpfs/tardis/home/jq2uw/llm_nicu_vitalsigns/clip_env/lib/R'\n",
    "# os.environ['R_HOME'] = r_home\n",
    "# os.environ['R_LIBS'] = f\"{r_home}/library\"\n",
    "# os.environ['R_LIBS_USER'] = os.path.expanduser('~/R/goolf/4.3')\n",
    "# os.environ['LD_LIBRARY_PATH'] = f\"{r_home}/lib:\" + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 333\n",
      "using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from encoder import *\n",
    "from decoder import *\n",
    "from data import *\n",
    "from vital import *\n",
    "from train import *\n",
    "from eval import *\n",
    "from augmentor import *\n",
    "from describer import *\n",
    "from masker import *\n",
    "print(\"using device: \", device)\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import pkg_resources\n",
    "# print(pkg_resources.get_distribution('python-calamine').version)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (customize) configs\n",
    "overwrite = True\n",
    "model_name = 'testtest'\n",
    "text_config['cl']['die7d'] = True # udpate text_config here if needed\n",
    "text_config['split'] = True\n",
    "text_config['demo']['gre'] = True\n",
    "text_config['demo']['apgar_mage'] = True\n",
    "model_name = model_name + \"___\" + \"_\".join(get_true_components(text_config))\n",
    "\n",
    "update_config(\n",
    "    model_name = model_name,\n",
    "    ts_aug = False, # Data settings\n",
    "    ts_subseq = False,\n",
    "    ts_augsub = False,\n",
    "    downsample_size = 10,\n",
    "    balance = False,\n",
    "    block_target = False,\n",
    "    embedded_dim = 32,\n",
    "    batch_size = 2048, # Data loader settings\n",
    "    ts_global_normalize = True,\n",
    "    ts_local_normalize = False,# True,\n",
    "    patience = 100, # Training settings\n",
    "    num_saves = 20,\n",
    "    num_epochs = 10000,\n",
    "    init_lr = 1e-4,\n",
    "    text_config = text_config,\n",
    "    text_col_ls = ['cl_event', 'ts_description', 'demo_ga', 'demo_weight', 'demo_apgar', 'demo_mother']\n",
    ")\n",
    "config_dict = get_config_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of patients with positive labels:\n",
      "VitalID\n",
      "1018    8\n",
      "5170    8\n",
      "1464    8\n",
      "2361    8\n",
      "2791    8\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=9)]: Using backend LokyBackend with 9 concurrent workers.\n",
      "[Parallel(n_jobs=9)]: Done  32 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=9)]: Done 3739 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=9)]: Done 63138 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=9)]: Done 65353 out of 65353 | elapsed:   13.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This infant will survive.  This infant has gestational age 24 weeks. Birth weight is 360 grams. This infant is Female Black non-Hispanic. The Apgar5 scores 6. Mother is 21 years old.    Moderate variability.  Very low amount of consecutive increases. \n",
      "\n",
      "Available text columns:\n",
      "['cl_event', 'ts_description', 'demo_ga', 'demo_weight', 'demo_gender', 'demo_race', 'demo_ethnicity', 'demo_apgar', 'demo_mother', 'cl_die7d']\n",
      "\n",
      "Sample of patients with positive labels:\n",
      "TestID\n",
      "817     8\n",
      "1903    8\n",
      "801     8\n",
      "508     8\n",
      "2518    8\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=9)]: Using backend LokyBackend with 9 concurrent workers.\n",
      "[Parallel(n_jobs=9)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=9)]: Done 9454 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=9)]: Done 41454 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=9)]: Done 61553 out of 61570 | elapsed:    8.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=9)]: Done 61570 out of 61570 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This infant will survive.  This infant has gestational age 33 weeks. Birth weight is 2630 grams. This infant is Male non-Black non-Hispanic. The Apgar5 scores 9. Mother is 26 years old.    High variability.  Low amount of consecutive increases. \n",
      "\n",
      "Available text columns:\n",
      "['cl_event', 'ts_description', 'demo_ga', 'demo_weight', 'demo_gender', 'demo_race', 'demo_ethnicity', 'demo_apgar', 'demo_mother', 'cl_die7d']\n",
      "After downsampling:\n",
      "cl_event\n",
      "This infant will die in 7 days.     384\n",
      "This infant will survive.            10\n",
      "Name: count, dtype: int64\n",
      "After downsampling:\n",
      "cl_event\n",
      "This infant will die in 7 days.     241\n",
      "This infant will survive.            10\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTimeSeries/llm_nicu_vitalsigns/clip_env/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cl_event\n",
      "This infant will die in 7 days.     384\n",
      "This infant will survive.            10\n",
      "Name: count, dtype: int64\n",
      "cl_event\n",
      "This infant will die in 7 days.     241\n",
      "This infant will survive.            10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# run preprocess.py to ready the data\n",
    "with open('preprocess.py', 'r') as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize VITAL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                                                 Param #\n",
      "===============================================================================================\n",
      "VITAL3D                                                                1\n",
      "├─TSVAEEncoder: 1-1                                                    --\n",
      "│    └─Sequential: 2-1                                                 --\n",
      "│    │    └─Linear: 3-1                                                77,056\n",
      "│    │    └─LeakyReLU: 3-2                                             --\n",
      "│    │    └─Linear: 3-3                                                131,584\n",
      "│    │    └─LeakyReLU: 3-4                                             --\n",
      "│    │    └─Linear: 3-5                                                262,656\n",
      "│    │    └─LeakyReLU: 3-6                                             --\n",
      "│    │    └─Linear: 3-7                                                262,656\n",
      "│    │    └─LeakyReLU: 3-8                                             --\n",
      "│    │    └─Linear: 3-9                                                262,656\n",
      "│    │    └─LeakyReLU: 3-10                                            --\n",
      "│    │    └─Linear: 3-11                                               131,328\n",
      "│    │    └─LeakyReLU: 3-12                                            --\n",
      "│    │    └─Linear: 3-13                                               32,896\n",
      "│    │    └─LeakyReLU: 3-14                                            --\n",
      "│    └─Linear: 2-2                                                     4,128\n",
      "│    └─Linear: 2-3                                                     4,128\n",
      "├─TextEncoderWithAttention: 1-2                                        32\n",
      "│    └─ModuleList: 2-4                                                 --\n",
      "│    │    └─Sequential: 3-15                                           535,712\n",
      "│    │    └─Sequential: 3-16                                           535,712\n",
      "│    │    └─Sequential: 3-17                                           535,712\n",
      "│    │    └─Sequential: 3-18                                           535,712\n",
      "│    │    └─Sequential: 3-19                                           535,712\n",
      "│    │    └─Sequential: 3-20                                           535,712\n",
      "│    └─MultiheadAttention: 2-5                                         3,168\n",
      "│    │    └─NonDynamicallyQuantizableLinear: 3-21                      1,056\n",
      "├─TSVAEDecoder: 1-3                                                    --\n",
      "│    └─Sequential: 2-6                                                 --\n",
      "│    │    └─Linear: 3-22                                               4,224\n",
      "│    │    └─LeakyReLU: 3-23                                            --\n",
      "│    │    └─Linear: 3-24                                               33,024\n",
      "│    │    └─LeakyReLU: 3-25                                            --\n",
      "│    │    └─Linear: 3-26                                               131,584\n",
      "│    │    └─LeakyReLU: 3-27                                            --\n",
      "│    │    └─Linear: 3-28                                               131,328\n",
      "│    │    └─LeakyReLU: 3-29                                            --\n",
      "│    │    └─Linear: 3-30                                               32,896\n",
      "│    │    └─LeakyReLU: 3-31                                            --\n",
      "│    │    └─Linear: 3-32                                               38,700\n",
      "===============================================================================================\n",
      "Total params: 4,759,373\n",
      "Trainable params: 4,759,373\n",
      "Non-trainable params: 0\n",
      "===============================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTimeSeries/llm_nicu_vitalsigns/clip_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# customize model\n",
    "if overwrite:    \n",
    "    # check if ts_f_dim is already in the memory\n",
    "    if 'ts_f_dim' not in locals():\n",
    "        # get the dimension out\n",
    "        if config_dict['3d']:\n",
    "            ts_f_dim, tx_f_dim_ls, labels_dim = get_features3d(df_train.iloc[:1,:], \n",
    "                                                                config_dict['text_encoder_name'], \n",
    "                                                                config_dict['ts_normalize_mean'],\n",
    "                                                                config_dict['ts_normalize_std'],\n",
    "                                                                text_col_ls = config_dict['text_col_ls'])\n",
    "        else:\n",
    "            ts_f_dim, tx_f_dim, labels_dim = get_features(df_train.iloc[:1,:], \n",
    "                                                            config_dict['text_encoder_name'], \n",
    "                                                            config_dict['ts_normalize_mean'],\n",
    "                                                            config_dict['ts_normalize_std'])\n",
    "    \n",
    "    ts_encoder = None\n",
    "    ts_decoder = None\n",
    "    # #--- custom ts encoder in encoder.py ---\n",
    "    # e = MLPEncoder(\n",
    "    #     ts_dim=ts_f_dim.shape[1], \n",
    "    #     output_dim=config_dict['embedded_dim']\n",
    "    # )\n",
    "    # ts_encoder = TSVAEEncoderWrapper(e)\n",
    "    # # --- custom ts decoder in decoder.py ---\n",
    "    # d = MLPDecoder(\n",
    "    #     ts_dim=ts_f_dim.shape[1], \n",
    "    #     output_dim=config_dict['embedded_dim']\n",
    "    # )\n",
    "    # ts_decoder = TSVAEDecoderWrapper(d)\n",
    "\n",
    "    if config_dict['3d']:\n",
    "        model = VITAL3D(\n",
    "                    ts_dim=ts_f_dim.shape[1],\n",
    "                    text_dim=tx_f_dim_ls[0].shape[1],\n",
    "                    n_text=len(tx_f_dim_ls),\n",
    "                    output_dim=config_dict['embedded_dim'],\n",
    "                    ts_encoder=ts_encoder,\n",
    "                    ts_decoder=ts_decoder\n",
    "                )\n",
    "    else:\n",
    "        model = VITAL(\n",
    "                    ts_dim=ts_f_dim.shape[1],\n",
    "                    text_dim=tx_f_dim.shape[1],\n",
    "                    output_dim=config_dict['embedded_dim'],\n",
    "                    ts_encoder=ts_encoder,\n",
    "                    ts_decoder=ts_decoder\n",
    "                )\n",
    "    update_config(model_init = model)\n",
    "    config_dict = get_config_dict()\n",
    "    \n",
    "    # ------------------------- ready training -------------------------\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config_dict['init_lr'],\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min',\n",
    "        factor=0.9,         \n",
    "        patience=config_dict['patience'],       \n",
    "        verbose=True,\n",
    "        min_lr=1e-10,        \n",
    "        threshold=1e-4,      \n",
    "        cooldown=20          \n",
    "    )\n",
    "\n",
    "    kl_annealer = KLAnnealer(start=1.0, \n",
    "                             end=1.0, \n",
    "                             epochs=10000) # for the first 1000 epochs, favor reconstruction more\n",
    "\n",
    "\n",
    "    train_eval_metrics_list = []\n",
    "    test_eval_metrics_list = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # ------------------------- ready output directory -------------------------\n",
    "    import shutil\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir)\n",
    "    # torch.save(config_dict, config_path)\n",
    "    # overwrite = False # reset overwrite to False\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 9.455454\n",
      "\tTesting Loss: 8.300138\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 9.177364\n",
      "\tTesting Loss: 7.797813\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 8.471599\n",
      "\tTesting Loss: 7.606916\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 8.127148\n",
      "\tTesting Loss: 7.583002\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 8.129177\n",
      "\tTesting Loss: 7.426811\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 8.057659\n",
      "\tTesting Loss: 7.245516\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 7.786929\n",
      "\tTesting Loss: 7.430506\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 8.067180\n",
      "\tTesting Loss: 6.780373\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 7.442846\n",
      "\tTesting Loss: 6.896765\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 7.352412\n",
      "\tTesting Loss: 6.655729\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.686   |   0.615\n",
      "Precision |   0.976   |   0.940\n",
      "Recall    |   0.529   |   0.456\n",
      "AUROC     |   0.495   |   0.339\n",
      "AUPRC     |   0.976   |   0.939\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 7.358737\n",
      "\tTesting Loss: 6.516587\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 7.360660\n",
      "\tTesting Loss: 6.465622\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 7.185787\n",
      "\tTesting Loss: 6.431488\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 6.920984\n",
      "\tTesting Loss: 6.453685\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 6.917586\n",
      "\tTesting Loss: 6.293098\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 6.915120\n",
      "\tTesting Loss: 6.267936\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 6.830670\n",
      "\tTesting Loss: 6.323245\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 6.825240\n",
      "\tTesting Loss: 6.149865\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 6.816829\n",
      "\tTesting Loss: 6.052521\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 6.713635\n",
      "\tTesting Loss: 6.018998\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.645   |   0.648\n",
      "Precision |   0.964   |   0.975\n",
      "Recall    |   0.484   |   0.485\n",
      "AUROC     |   0.431   |   0.587\n",
      "AUPRC     |   0.976   |   0.960\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 6.670687\n",
      "\tTesting Loss: 5.997888\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 6.496181\n",
      "\tTesting Loss: 5.941237\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 6.456078\n",
      "\tTesting Loss: 6.010950\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 6.689662\n",
      "\tTesting Loss: 5.948542\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 6.390078\n",
      "\tTesting Loss: 5.874815\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 6.360253\n",
      "\tTesting Loss: 5.825302\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 6.323575\n",
      "\tTesting Loss: 5.811533\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 6.274510\n",
      "\tTesting Loss: 5.776468\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 6.259872\n",
      "\tTesting Loss: 5.758766\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 6.252968\n",
      "\tTesting Loss: 5.772528\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.657   |   0.637\n",
      "Precision |   0.990   |   0.958\n",
      "Recall    |   0.492   |   0.477\n",
      "AUROC     |   0.581   |   0.542\n",
      "AUPRC     |   0.984   |   0.970\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 6.240613\n",
      "\tTesting Loss: 5.684107\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 6.214331\n",
      "\tTesting Loss: 5.698427\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 6.187206\n",
      "\tTesting Loss: 5.680352\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 6.211643\n",
      "\tTesting Loss: 5.660218\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 6.144102\n",
      "\tTesting Loss: 5.644545\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 6.156136\n",
      "\tTesting Loss: 5.627024\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 6.124722\n",
      "\tTesting Loss: 5.619928\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 6.128439\n",
      "\tTesting Loss: 5.612148\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 6.105086\n",
      "\tTesting Loss: 5.616073\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 6.118499\n",
      "\tTesting Loss: 5.584682\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.599   |   0.618\n",
      "Precision |   0.988   |   0.973\n",
      "Recall    |   0.430   |   0.452\n",
      "AUROC     |   0.612   |   0.554\n",
      "AUPRC     |   0.985   |   0.966\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 6.083991\n",
      "\tTesting Loss: 5.577918\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 6.079589\n",
      "\tTesting Loss: 5.591802\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 6.079287\n",
      "\tTesting Loss: 5.581379\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 6.083178\n",
      "\tTesting Loss: 5.569340\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 6.042962\n",
      "\tTesting Loss: 5.562023\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 6.047426\n",
      "\tTesting Loss: 5.574282\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 6.055094\n",
      "\tTesting Loss: 5.568734\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 6.062747\n",
      "\tTesting Loss: 5.555408\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 6.037791\n",
      "\tTesting Loss: 5.546092\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 6.035477\n",
      "\tTesting Loss: 5.546240\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.555   |   0.606\n",
      "Precision |   0.974   |   0.955\n",
      "Recall    |   0.388   |   0.444\n",
      "AUROC     |   0.559   |   0.395\n",
      "AUPRC     |   0.981   |   0.956\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 6.034287\n",
      "\tTesting Loss: 5.544519\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 6.029302\n",
      "\tTesting Loss: 5.541243\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 6.037930\n",
      "\tTesting Loss: 5.539598\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 6.028088\n",
      "\tTesting Loss: 5.544988\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 6.028329\n",
      "\tTesting Loss: 5.538240\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 6.004895\n",
      "\tTesting Loss: 5.531365\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 6.014821\n",
      "\tTesting Loss: 5.536798\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 6.027465\n",
      "\tTesting Loss: 5.535073\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 6.023754\n",
      "\tTesting Loss: 5.531632\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 6.000519\n",
      "\tTesting Loss: 5.532547\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.558   |   0.527\n",
      "Precision |   0.974   |   0.946\n",
      "Recall    |   0.391   |   0.365\n",
      "AUROC     |   0.502   |   0.391\n",
      "AUPRC     |   0.973   |   0.951\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 6.011405\n",
      "\tTesting Loss: 5.538842\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 6.012553\n",
      "\tTesting Loss: 5.531314\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.990029\n",
      "\tTesting Loss: 5.532794\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.993347\n",
      "\tTesting Loss: 5.531356\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.997247\n",
      "\tTesting Loss: 5.529759\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 6.008273\n",
      "\tTesting Loss: 5.528506\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.987864\n",
      "\tTesting Loss: 5.533646\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.988599\n",
      "\tTesting Loss: 5.530819\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.991673\n",
      "\tTesting Loss: 5.530612\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.985178\n",
      "\tTesting Loss: 5.529206\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.607   |   0.621\n",
      "Precision |   0.977   |   0.973\n",
      "Recall    |   0.440   |   0.456\n",
      "AUROC     |   0.522   |   0.522\n",
      "AUPRC     |   0.981   |   0.965\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.998104\n",
      "\tTesting Loss: 5.529919\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 6.005794\n",
      "\tTesting Loss: 5.529382\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.991702\n",
      "\tTesting Loss: 5.529993\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.992172\n",
      "\tTesting Loss: 5.527889\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.989436\n",
      "\tTesting Loss: 5.528489\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.988076\n",
      "\tTesting Loss: 5.527081\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.986539\n",
      "\tTesting Loss: 5.528270\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.987716\n",
      "\tTesting Loss: 5.529313\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.987629\n",
      "\tTesting Loss: 5.527193\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.989759\n",
      "\tTesting Loss: 5.529787\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.602   |   0.658\n",
      "Precision |   0.966   |   0.968\n",
      "Recall    |   0.438   |   0.498\n",
      "AUROC     |   0.475   |   0.502\n",
      "AUPRC     |   0.975   |   0.965\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.993572\n",
      "\tTesting Loss: 5.527406\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.990504\n",
      "\tTesting Loss: 5.529149\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.990336\n",
      "\tTesting Loss: 5.528114\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.984097\n",
      "\tTesting Loss: 5.528798\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.986047\n",
      "\tTesting Loss: 5.528889\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.975738\n",
      "\tTesting Loss: 5.527627\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.991472\n",
      "\tTesting Loss: 5.528595\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.986423\n",
      "\tTesting Loss: 5.527443\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.980107\n",
      "\tTesting Loss: 5.526917\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.990418\n",
      "\tTesting Loss: 5.528697\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.630   |   0.571\n",
      "Precision |   0.973   |   0.961\n",
      "Recall    |   0.466   |   0.407\n",
      "AUROC     |   0.476   |   0.503\n",
      "AUPRC     |   0.967   |   0.960\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.990859\n",
      "\tTesting Loss: 5.526259\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.979304\n",
      "\tTesting Loss: 5.528571\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.986501\n",
      "\tTesting Loss: 5.527987\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.986021\n",
      "\tTesting Loss: 5.530295\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.984329\n",
      "\tTesting Loss: 5.527400\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.981738\n",
      "\tTesting Loss: 5.526713\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.985049\n",
      "\tTesting Loss: 5.527153\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.983997\n",
      "\tTesting Loss: 5.526701\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.979988\n",
      "\tTesting Loss: 5.529725\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.988855\n",
      "\tTesting Loss: 5.528030\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.649   |   0.658\n",
      "Precision |   0.974   |   0.968\n",
      "Recall    |   0.487   |   0.498\n",
      "AUROC     |   0.496   |   0.537\n",
      "AUPRC     |   0.979   |   0.961\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.982888\n",
      "\tTesting Loss: 5.528802\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.985643\n",
      "\tTesting Loss: 5.526209\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.981544\n",
      "\tTesting Loss: 5.528065\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.983166\n",
      "\tTesting Loss: 5.527807\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.985445\n",
      "\tTesting Loss: 5.527845\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.988943\n",
      "\tTesting Loss: 5.527496\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.975734\n",
      "\tTesting Loss: 5.527561\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.972336\n",
      "\tTesting Loss: 5.526475\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.974730\n",
      "\tTesting Loss: 5.529543\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.991343\n",
      "\tTesting Loss: 5.527779\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.666   |   0.622\n",
      "Precision |   0.965   |   0.957\n",
      "Recall    |   0.508   |   0.461\n",
      "AUROC     |   0.334   |   0.415\n",
      "AUPRC     |   0.966   |   0.955\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.980331\n",
      "\tTesting Loss: 5.527417\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.983714\n",
      "\tTesting Loss: 5.529639\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.981102\n",
      "\tTesting Loss: 5.527131\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.977572\n",
      "\tTesting Loss: 5.527486\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.982347\n",
      "\tTesting Loss: 5.527469\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.973547\n",
      "\tTesting Loss: 5.529490\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.984316\n",
      "\tTesting Loss: 5.528849\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.983746\n",
      "\tTesting Loss: 5.526622\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.979217\n",
      "\tTesting Loss: 5.526113\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.981606\n",
      "\tTesting Loss: 5.529235\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.661   |   0.650\n",
      "Precision |   0.995   |   0.952\n",
      "Recall    |   0.495   |   0.494\n",
      "AUROC     |   0.705   |   0.412\n",
      "AUPRC     |   0.991   |   0.949\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.982891\n",
      "\tTesting Loss: 5.528367\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.976538\n",
      "\tTesting Loss: 5.528263\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.978633\n",
      "\tTesting Loss: 5.527785\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.973708\n",
      "\tTesting Loss: 5.528804\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.976424\n",
      "\tTesting Loss: 5.526188\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.978179\n",
      "\tTesting Loss: 5.527289\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.980466\n",
      "\tTesting Loss: 5.528936\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.973127\n",
      "\tTesting Loss: 5.525736\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.975930\n",
      "\tTesting Loss: 5.528602\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.980335\n",
      "\tTesting Loss: 5.527972\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.686   |   0.654\n",
      "Precision |   0.976   |   0.952\n",
      "Recall    |   0.529   |   0.498\n",
      "AUROC     |   0.482   |   0.400\n",
      "AUPRC     |   0.975   |   0.951\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.974543\n",
      "\tTesting Loss: 5.530668\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.978377\n",
      "\tTesting Loss: 5.529318\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.975679\n",
      "\tTesting Loss: 5.529591\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.976905\n",
      "\tTesting Loss: 5.530105\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.976915\n",
      "\tTesting Loss: 5.534242\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.978199\n",
      "\tTesting Loss: 5.532017\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.981398\n",
      "\tTesting Loss: 5.528593\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.973866\n",
      "\tTesting Loss: 5.528249\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.972761\n",
      "\tTesting Loss: 5.531203\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.979788\n",
      "\tTesting Loss: 5.529410\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.609   |   0.628\n",
      "Precision |   0.961   |   0.950\n",
      "Recall    |   0.445   |   0.469\n",
      "AUROC     |   0.438   |   0.412\n",
      "AUPRC     |   0.975   |   0.959\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.974499\n",
      "\tTesting Loss: 5.531949\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.975307\n",
      "\tTesting Loss: 5.531009\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.972947\n",
      "\tTesting Loss: 5.532222\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.968440\n",
      "\tTesting Loss: 5.531500\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.971448\n",
      "\tTesting Loss: 5.528278\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.970311\n",
      "\tTesting Loss: 5.534278\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.967486\n",
      "\tTesting Loss: 5.535812\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.976802\n",
      "\tTesting Loss: 5.528152\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.970793\n",
      "\tTesting Loss: 5.537509\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.974608\n",
      "\tTesting Loss: 5.536935\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.637   |   0.667\n",
      "Precision |   0.958   |   0.947\n",
      "Recall    |   0.477   |   0.515\n",
      "AUROC     |   0.305   |   0.439\n",
      "AUPRC     |   0.965   |   0.964\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.963526\n",
      "\tTesting Loss: 5.544245\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.973501\n",
      "\tTesting Loss: 5.537614\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.970677\n",
      "\tTesting Loss: 5.544917\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.969659\n",
      "\tTesting Loss: 5.535205\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.966528\n",
      "\tTesting Loss: 5.542019\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.963563\n",
      "\tTesting Loss: 5.537020\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.966726\n",
      "\tTesting Loss: 5.542281\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.970724\n",
      "\tTesting Loss: 5.543427\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.954005\n",
      "\tTesting Loss: 5.548794\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.955736\n",
      "\tTesting Loss: 5.543216\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.659   |   0.648\n",
      "Precision |   0.965   |   0.959\n",
      "Recall    |   0.500   |   0.490\n",
      "AUROC     |   0.362   |   0.572\n",
      "AUPRC     |   0.970   |   0.972\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.957516\n",
      "\tTesting Loss: 5.547888\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.958422\n",
      "\tTesting Loss: 5.545641\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.951198\n",
      "\tTesting Loss: 5.542045\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.944255\n",
      "\tTesting Loss: 5.537751\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.952044\n",
      "\tTesting Loss: 5.536017\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.954682\n",
      "\tTesting Loss: 5.538579\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.943918\n",
      "\tTesting Loss: 5.550426\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.921468\n",
      "\tTesting Loss: 5.548100\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.913612\n",
      "\tTesting Loss: 5.561459\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.951500\n",
      "\tTesting Loss: 5.546435\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.640   |   0.679\n",
      "Precision |   0.973   |   0.955\n",
      "Recall    |   0.477   |   0.527\n",
      "AUROC     |   0.487   |   0.483\n",
      "AUPRC     |   0.972   |   0.961\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.930108\n",
      "\tTesting Loss: 5.587483\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.963455\n",
      "\tTesting Loss: 5.556891\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.920639\n",
      "\tTesting Loss: 5.606209\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.993522\n",
      "\tTesting Loss: 5.606151\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.978812\n",
      "\tTesting Loss: 5.543586\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.940422\n",
      "\tTesting Loss: 5.616924\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.969728\n",
      "\tTesting Loss: 5.562471\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.925379\n",
      "\tTesting Loss: 5.564891\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.936619\n",
      "\tTesting Loss: 5.567862\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.945321\n",
      "\tTesting Loss: 5.536912\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.623   |   0.612\n",
      "Precision |   0.972   |   0.964\n",
      "Recall    |   0.458   |   0.448\n",
      "AUROC     |   0.464   |   0.515\n",
      "AUPRC     |   0.971   |   0.962\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.909550\n",
      "\tTesting Loss: 5.568717\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.918721\n",
      "\tTesting Loss: 5.534684\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.909945\n",
      "\tTesting Loss: 5.539281\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.936391\n",
      "\tTesting Loss: 5.541251\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.904788\n",
      "\tTesting Loss: 5.578353\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.912717\n",
      "\tTesting Loss: 5.555253\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.900242\n",
      "\tTesting Loss: 5.542936\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.888952\n",
      "\tTesting Loss: 5.568567\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.897130\n",
      "\tTesting Loss: 5.557649\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.895491\n",
      "\tTesting Loss: 5.554988\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.642   |   0.633\n",
      "Precision |   0.964   |   0.958\n",
      "Recall    |   0.482   |   0.473\n",
      "AUROC     |   0.424   |   0.512\n",
      "AUPRC     |   0.970   |   0.964\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.896939\n",
      "\tTesting Loss: 5.545258\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.883811\n",
      "\tTesting Loss: 5.516372\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.887175\n",
      "\tTesting Loss: 5.537087\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.890352\n",
      "\tTesting Loss: 5.545447\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.876495\n",
      "\tTesting Loss: 5.545870\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.871045\n",
      "\tTesting Loss: 5.538185\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.859442\n",
      "\tTesting Loss: 5.544041\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.872237\n",
      "\tTesting Loss: 5.539885\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.872817\n",
      "\tTesting Loss: 5.563363\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.858735\n",
      "\tTesting Loss: 5.546705\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.629   |   0.609\n",
      "Precision |   0.968   |   0.932\n",
      "Recall    |   0.466   |   0.452\n",
      "AUROC     |   0.412   |   0.346\n",
      "AUPRC     |   0.970   |   0.939\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.858769\n",
      "\tTesting Loss: 5.556727\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.860005\n",
      "\tTesting Loss: 5.565213\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.857964\n",
      "\tTesting Loss: 5.548913\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.846607\n",
      "\tTesting Loss: 5.555001\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.849873\n",
      "\tTesting Loss: 5.560368\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.845240\n",
      "\tTesting Loss: 5.559717\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.847928\n",
      "\tTesting Loss: 5.545536\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.843941\n",
      "\tTesting Loss: 5.550869\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.850960\n",
      "\tTesting Loss: 5.569539\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.844160\n",
      "\tTesting Loss: 5.544734\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.654   |   0.681\n",
      "Precision |   0.984   |   0.977\n",
      "Recall    |   0.490   |   0.523\n",
      "AUROC     |   0.613   |   0.639\n",
      "AUPRC     |   0.981   |   0.974\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.831050\n",
      "\tTesting Loss: 5.573972\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.846078\n",
      "\tTesting Loss: 5.559937\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.831493\n",
      "\tTesting Loss: 5.559892\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.845906\n",
      "\tTesting Loss: 5.539790\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.828701\n",
      "\tTesting Loss: 5.556160\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.844413\n",
      "\tTesting Loss: 5.528833\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.823973\n",
      "\tTesting Loss: 5.622229\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.883042\n",
      "\tTesting Loss: 5.642793\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.885000\n",
      "\tTesting Loss: 5.563430\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.818754\n",
      "\tTesting Loss: 5.631875\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.683   |   0.592\n",
      "Precision |   0.980   |   0.963\n",
      "Recall    |   0.523   |   0.427\n",
      "AUROC     |   0.580   |   0.458\n",
      "AUPRC     |   0.982   |   0.960\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.904503\n",
      "\tTesting Loss: 5.657784\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.907146\n",
      "\tTesting Loss: 5.555474\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.834081\n",
      "\tTesting Loss: 5.613751\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.864217\n",
      "\tTesting Loss: 5.629596\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.867529\n",
      "\tTesting Loss: 5.581168\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.810198\n",
      "\tTesting Loss: 5.634564\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.848529\n",
      "\tTesting Loss: 5.680167\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.886454\n",
      "\tTesting Loss: 5.646242\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.837354\n",
      "\tTesting Loss: 5.626069\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.811520\n",
      "\tTesting Loss: 5.647895\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.653   |   0.650\n",
      "Precision |   0.979   |   0.938\n",
      "Recall    |   0.490   |   0.498\n",
      "AUROC     |   0.560   |   0.318\n",
      "AUPRC     |   0.981   |   0.951\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.821079\n",
      "\tTesting Loss: 5.585478\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.815626\n",
      "\tTesting Loss: 5.586684\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.813805\n",
      "\tTesting Loss: 5.639182\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.820087\n",
      "\tTesting Loss: 5.627518\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.804646\n",
      "\tTesting Loss: 5.642799\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.814005\n",
      "\tTesting Loss: 5.625215\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.798708\n",
      "\tTesting Loss: 5.586554\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.770295\n",
      "\tTesting Loss: 5.573963\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.791451\n",
      "\tTesting Loss: 5.592295\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.789524\n",
      "\tTesting Loss: 5.605453\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.673   |   0.646\n",
      "Precision |   0.971   |   0.967\n",
      "Recall    |   0.516   |   0.485\n",
      "AUROC     |   0.471   |   0.635\n",
      "AUPRC     |   0.976   |   0.974\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.789299\n",
      "\tTesting Loss: 5.601470\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.781802\n",
      "\tTesting Loss: 5.579358\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.779334\n",
      "\tTesting Loss: 5.584924\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.778334\n",
      "\tTesting Loss: 5.593337\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.780372\n",
      "\tTesting Loss: 5.591793\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.775346\n",
      "\tTesting Loss: 5.582800\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.761036\n",
      "\tTesting Loss: 5.624118\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.756519\n",
      "\tTesting Loss: 5.641043\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.764459\n",
      "\tTesting Loss: 5.629681\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.753308\n",
      "\tTesting Loss: 5.642488\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.661   |   0.667\n",
      "Precision |   0.985   |   0.961\n",
      "Recall    |   0.497   |   0.510\n",
      "AUROC     |   0.608   |   0.455\n",
      "AUPRC     |   0.982   |   0.958\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.745902\n",
      "\tTesting Loss: 5.645029\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.769781\n",
      "\tTesting Loss: 5.701764\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.771135\n",
      "\tTesting Loss: 5.672753\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.776489\n",
      "\tTesting Loss: 5.624453\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.746456\n",
      "\tTesting Loss: 5.637822\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.745342\n",
      "\tTesting Loss: 5.640698\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.745739\n",
      "\tTesting Loss: 5.648563\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.748997\n",
      "\tTesting Loss: 5.653198\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.709455\n",
      "\tTesting Loss: 5.660806\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.743089\n",
      "\tTesting Loss: 5.686417\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.666   |   0.681\n",
      "Precision |   0.985   |   0.977\n",
      "Recall    |   0.503   |   0.523\n",
      "AUROC     |   0.610   |   0.631\n",
      "AUPRC     |   0.980   |   0.975\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.713031\n",
      "\tTesting Loss: 5.682465\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.734855\n",
      "\tTesting Loss: 5.689017\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.712183\n",
      "\tTesting Loss: 5.715127\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.742209\n",
      "\tTesting Loss: 5.713039\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.738579\n",
      "\tTesting Loss: 5.735908\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.726355\n",
      "\tTesting Loss: 5.728492\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.736971\n",
      "\tTesting Loss: 5.701566\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.698709\n",
      "\tTesting Loss: 5.720572\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.704868\n",
      "\tTesting Loss: 5.748035\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.706108\n",
      "\tTesting Loss: 5.700563\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.642   |   0.700\n",
      "Precision |   0.984   |   0.971\n",
      "Recall    |   0.477   |   0.548\n",
      "AUROC     |   0.614   |   0.612\n",
      "AUPRC     |   0.978   |   0.974\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.698163\n",
      "\tTesting Loss: 5.714205\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.725041\n",
      "\tTesting Loss: 5.672496\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.701357\n",
      "\tTesting Loss: 5.690141\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.701452\n",
      "\tTesting Loss: 5.701883\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.690499\n",
      "\tTesting Loss: 5.773689\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.699150\n",
      "\tTesting Loss: 5.727466\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.679197\n",
      "\tTesting Loss: 5.716317\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.692266\n",
      "\tTesting Loss: 5.701927\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.675725\n",
      "\tTesting Loss: 5.743578\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.680102\n",
      "\tTesting Loss: 5.751981\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.623   |   0.626\n",
      "Precision |   0.962   |   0.957\n",
      "Recall    |   0.461   |   0.465\n",
      "AUROC     |   0.409   |   0.496\n",
      "AUPRC     |   0.965   |   0.968\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.671723\n",
      "\tTesting Loss: 5.768674\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.663404\n",
      "\tTesting Loss: 5.798978\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.658015\n",
      "\tTesting Loss: 5.771388\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.661791\n",
      "\tTesting Loss: 5.771986\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.656911\n",
      "\tTesting Loss: 5.794151\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.659259\n",
      "\tTesting Loss: 5.740371\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.650718\n",
      "\tTesting Loss: 5.752172\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.650784\n",
      "\tTesting Loss: 5.776755\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.626311\n",
      "\tTesting Loss: 5.768864\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.650963\n",
      "\tTesting Loss: 5.812163\n",
      "\tLearning Rate: 0.000100000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.672   |   0.679\n",
      "Precision |   0.975   |   0.955\n",
      "Recall    |   0.513   |   0.527\n",
      "AUROC     |   0.465   |   0.410\n",
      "AUPRC     |   0.970   |   0.957\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.623507\n",
      "\tTesting Loss: 5.804068\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.597108\n",
      "\tTesting Loss: 5.852481\n",
      "\tLearning Rate: 0.000100000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.631474\n",
      "\tTesting Loss: 5.910037\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.623355\n",
      "\tTesting Loss: 5.784388\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.588408\n",
      "\tTesting Loss: 5.815498\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.621903\n",
      "\tTesting Loss: 5.830227\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.578597\n",
      "\tTesting Loss: 5.923134\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.609081\n",
      "\tTesting Loss: 5.866826\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.579399\n",
      "\tTesting Loss: 5.829590\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.567045\n",
      "\tTesting Loss: 5.900687\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.659   |   0.658\n",
      "Precision |   0.974   |   0.968\n",
      "Recall    |   0.497   |   0.498\n",
      "AUROC     |   0.509   |   0.552\n",
      "AUPRC     |   0.977   |   0.975\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.578276\n",
      "\tTesting Loss: 5.865494\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.562208\n",
      "\tTesting Loss: 5.880716\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.537910\n",
      "\tTesting Loss: 5.935034\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.541251\n",
      "\tTesting Loss: 5.942026\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.514764\n",
      "\tTesting Loss: 6.029394\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.535310\n",
      "\tTesting Loss: 5.991266\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.498667\n",
      "\tTesting Loss: 5.989056\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.520779\n",
      "\tTesting Loss: 6.115642\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.578346\n",
      "\tTesting Loss: 5.911145\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.518143\n",
      "\tTesting Loss: 5.943971\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.625   |   0.637\n",
      "Precision |   0.973   |   0.974\n",
      "Recall    |   0.461   |   0.473\n",
      "AUROC     |   0.448   |   0.535\n",
      "AUPRC     |   0.975   |   0.966\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.553727\n",
      "\tTesting Loss: 5.932475\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.514793\n",
      "\tTesting Loss: 5.926678\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.500893\n",
      "\tTesting Loss: 5.857018\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.526124\n",
      "\tTesting Loss: 5.868785\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.498216\n",
      "\tTesting Loss: 5.974765\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.522119\n",
      "\tTesting Loss: 5.889818\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.471476\n",
      "\tTesting Loss: 5.906409\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.524710\n",
      "\tTesting Loss: 5.935835\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.486491\n",
      "\tTesting Loss: 6.083469\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.504866\n",
      "\tTesting Loss: 6.045652\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.678   |   0.658\n",
      "Precision |   0.990   |   0.968\n",
      "Recall    |   0.516   |   0.498\n",
      "AUROC     |   0.673   |   0.487\n",
      "AUPRC     |   0.981   |   0.956\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.493066\n",
      "\tTesting Loss: 5.984190\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.464218\n",
      "\tTesting Loss: 5.968976\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.451111\n",
      "\tTesting Loss: 6.052870\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.464377\n",
      "\tTesting Loss: 5.963416\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.464221\n",
      "\tTesting Loss: 5.923646\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.419517\n",
      "\tTesting Loss: 5.982813\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.429764\n",
      "\tTesting Loss: 5.933046\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.415929\n",
      "\tTesting Loss: 6.037413\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.388463\n",
      "\tTesting Loss: 5.990258\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.401719\n",
      "\tTesting Loss: 6.108885\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.631   |   0.661\n",
      "Precision |   0.953   |   0.953\n",
      "Recall    |   0.471   |   0.506\n",
      "AUROC     |   0.191   |   0.483\n",
      "AUPRC     |   0.942   |   0.956\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.363416\n",
      "\tTesting Loss: 6.142929\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.371289\n",
      "\tTesting Loss: 6.080888\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.379956\n",
      "\tTesting Loss: 6.196592\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.425615\n",
      "\tTesting Loss: 6.033930\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.336661\n",
      "\tTesting Loss: 6.123002\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.550795\n",
      "\tTesting Loss: 6.043421\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.454441\n",
      "\tTesting Loss: 6.110752\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.423066\n",
      "\tTesting Loss: 6.075404\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.449319\n",
      "\tTesting Loss: 5.892928\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.374538\n",
      "\tTesting Loss: 5.959303\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.617   |   0.598\n",
      "Precision |   0.977   |   0.972\n",
      "Recall    |   0.451   |   0.432\n",
      "AUROC     |   0.464   |   0.559\n",
      "AUPRC     |   0.975   |   0.970\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.368064\n",
      "\tTesting Loss: 6.123000\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.367114\n",
      "\tTesting Loss: 6.095566\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.372002\n",
      "\tTesting Loss: 6.050588\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.380458\n",
      "\tTesting Loss: 6.104478\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.348126\n",
      "\tTesting Loss: 6.267271\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.377445\n",
      "\tTesting Loss: 6.227457\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.366660\n",
      "\tTesting Loss: 6.117686\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.335340\n",
      "\tTesting Loss: 6.088511\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.329816\n",
      "\tTesting Loss: 6.051985\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.272811\n",
      "\tTesting Loss: 6.113796\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.672   |   0.668\n",
      "Precision |   0.975   |   0.954\n",
      "Recall    |   0.513   |   0.515\n",
      "AUROC     |   0.463   |   0.409\n",
      "AUPRC     |   0.962   |   0.949\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.281920\n",
      "\tTesting Loss: 6.261624\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.317937\n",
      "\tTesting Loss: 6.171899\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.258327\n",
      "\tTesting Loss: 6.251522\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.395559\n",
      "\tTesting Loss: 6.271798\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.388880\n",
      "\tTesting Loss: 6.158437\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.254398\n",
      "\tTesting Loss: 6.196657\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.326731\n",
      "\tTesting Loss: 6.247194\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.277781\n",
      "\tTesting Loss: 6.231070\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.295835\n",
      "\tTesting Loss: 6.013803\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.261271\n",
      "\tTesting Loss: 6.064558\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.675   |   0.595\n",
      "Precision |   0.966   |   0.981\n",
      "Recall    |   0.518   |   0.427\n",
      "AUROC     |   0.365   |   0.525\n",
      "AUPRC     |   0.963   |   0.959\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.296247\n",
      "\tTesting Loss: 6.090605\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.214546\n",
      "\tTesting Loss: 6.450369\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.346667\n",
      "\tTesting Loss: 6.522334\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.346372\n",
      "\tTesting Loss: 6.264611\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.243006\n",
      "\tTesting Loss: 6.205471\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.266742\n",
      "\tTesting Loss: 6.149428\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.237286\n",
      "\tTesting Loss: 6.084957\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.322664\n",
      "\tTesting Loss: 6.106870\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.225863\n",
      "\tTesting Loss: 6.509843\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.328542\n",
      "\tTesting Loss: 6.574292\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.647   |   0.649\n",
      "Precision |   0.984   |   0.944\n",
      "Recall    |   0.482   |   0.494\n",
      "AUROC     |   0.668   |   0.382\n",
      "AUPRC     |   0.987   |   0.956\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.347911\n",
      "\tTesting Loss: 6.343935\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.283496\n",
      "\tTesting Loss: 6.187408\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.220932\n",
      "\tTesting Loss: 6.270920\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.275902\n",
      "\tTesting Loss: 6.263974\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.227595\n",
      "\tTesting Loss: 6.172921\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.232103\n",
      "\tTesting Loss: 6.202358\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.174400\n",
      "\tTesting Loss: 6.461752\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.289657\n",
      "\tTesting Loss: 6.415572\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.300692\n",
      "\tTesting Loss: 6.154558\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.206185\n",
      "\tTesting Loss: 6.186879\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.643   |   0.665\n",
      "Precision |   0.969   |   0.984\n",
      "Recall    |   0.482   |   0.502\n",
      "AUROC     |   0.406   |   0.667\n",
      "AUPRC     |   0.954   |   0.979\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.254452\n",
      "\tTesting Loss: 6.290374\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.207382\n",
      "\tTesting Loss: 6.298827\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.170467\n",
      "\tTesting Loss: 6.278986\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.226842\n",
      "\tTesting Loss: 6.276161\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.167052\n",
      "\tTesting Loss: 6.565758\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.199981\n",
      "\tTesting Loss: 6.564857\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.167684\n",
      "\tTesting Loss: 6.485474\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.169224\n",
      "\tTesting Loss: 6.382168\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.136478\n",
      "\tTesting Loss: 6.448675\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.200910\n",
      "\tTesting Loss: 6.361160\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.669   |   0.679\n",
      "Precision |   0.970   |   0.969\n",
      "Recall    |   0.510   |   0.523\n",
      "AUROC     |   0.461   |   0.589\n",
      "AUPRC     |   0.969   |   0.965\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.172797\n",
      "\tTesting Loss: 6.299533\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.165285\n",
      "\tTesting Loss: 6.419162\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.164561\n",
      "\tTesting Loss: 6.508384\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.155717\n",
      "\tTesting Loss: 6.340322\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.081447\n",
      "\tTesting Loss: 6.280360\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.139962\n",
      "\tTesting Loss: 6.378165\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.144409\n",
      "\tTesting Loss: 6.649179\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.143616\n",
      "\tTesting Loss: 6.635226\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.089215\n",
      "\tTesting Loss: 6.446383\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.150542\n",
      "\tTesting Loss: 6.332057\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.680   |   0.648\n",
      "Precision |   0.980   |   0.959\n",
      "Recall    |   0.521   |   0.490\n",
      "AUROC     |   0.516   |   0.605\n",
      "AUPRC     |   0.973   |   0.976\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.073653\n",
      "\tTesting Loss: 6.502396\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.172952\n",
      "\tTesting Loss: 6.440992\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.143117\n",
      "\tTesting Loss: 6.315888\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.147792\n",
      "\tTesting Loss: 6.344712\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.092300\n",
      "\tTesting Loss: 6.641717\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.161962\n",
      "\tTesting Loss: 6.545297\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.074401\n",
      "\tTesting Loss: 6.414210\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.111061\n",
      "\tTesting Loss: 6.390532\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.044824\n",
      "\tTesting Loss: 6.711295\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.111178\n",
      "\tTesting Loss: 6.728805\n",
      "\tLearning Rate: 0.000090000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.628   |   0.648\n",
      "Precision |   0.973   |   0.991\n",
      "Recall    |   0.464   |   0.481\n",
      "AUROC     |   0.520   |   0.706\n",
      "AUPRC     |   0.979   |   0.981\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.014489\n",
      "\tTesting Loss: 6.681443\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.209159\n",
      "\tTesting Loss: 6.540199\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 5.157796\n",
      "\tTesting Loss: 6.509079\n",
      "\tLearning Rate: 0.000090000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 5.017122\n",
      "\tTesting Loss: 6.588132\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.038949\n",
      "\tTesting Loss: 6.498220\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.003572\n",
      "\tTesting Loss: 6.591938\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.030492\n",
      "\tTesting Loss: 6.728986\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.020782\n",
      "\tTesting Loss: 6.659492\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 5.030369\n",
      "\tTesting Loss: 6.659707\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 5.043867\n",
      "\tTesting Loss: 6.564669\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.675   |   0.652\n",
      "Precision |   0.995   |   0.945\n",
      "Recall    |   0.510   |   0.498\n",
      "AUROC     |   0.690   |   0.391\n",
      "AUPRC     |   0.986   |   0.950\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.990543\n",
      "\tTesting Loss: 6.641440\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.982247\n",
      "\tTesting Loss: 6.647985\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.970927\n",
      "\tTesting Loss: 6.668809\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.935637\n",
      "\tTesting Loss: 6.751752\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 5.024175\n",
      "\tTesting Loss: 6.709786\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.980116\n",
      "\tTesting Loss: 6.708928\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.949403\n",
      "\tTesting Loss: 6.930459\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.899567\n",
      "\tTesting Loss: 6.984937\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.965018\n",
      "\tTesting Loss: 6.729425\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.906679\n",
      "\tTesting Loss: 6.786159\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.664   |   0.627\n",
      "Precision |   0.970   |   0.966\n",
      "Recall    |   0.505   |   0.465\n",
      "AUROC     |   0.427   |   0.527\n",
      "AUPRC     |   0.964   |   0.969\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.982465\n",
      "\tTesting Loss: 6.677070\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.958727\n",
      "\tTesting Loss: 6.638205\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.982387\n",
      "\tTesting Loss: 6.759190\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.951137\n",
      "\tTesting Loss: 6.994272\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.968046\n",
      "\tTesting Loss: 6.699842\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.907419\n",
      "\tTesting Loss: 6.673427\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.895646\n",
      "\tTesting Loss: 6.869996\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.882053\n",
      "\tTesting Loss: 7.032845\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.955647\n",
      "\tTesting Loss: 7.121377\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.880370\n",
      "\tTesting Loss: 6.978432\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.663   |   0.649\n",
      "Precision |   0.975   |   0.944\n",
      "Recall    |   0.503   |   0.494\n",
      "AUROC     |   0.546   |   0.483\n",
      "AUPRC     |   0.966   |   0.960\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.866120\n",
      "\tTesting Loss: 6.731647\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.952597\n",
      "\tTesting Loss: 6.759721\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.917081\n",
      "\tTesting Loss: 7.026744\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.881241\n",
      "\tTesting Loss: 6.995709\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.947358\n",
      "\tTesting Loss: 7.006734\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.862057\n",
      "\tTesting Loss: 7.231465\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 5.056654\n",
      "\tTesting Loss: 6.999859\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.034244\n",
      "\tTesting Loss: 6.678121\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.994348\n",
      "\tTesting Loss: 6.705213\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.936951\n",
      "\tTesting Loss: 7.198863\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.656   |   0.654\n",
      "Precision |   0.965   |   0.952\n",
      "Recall    |   0.497   |   0.498\n",
      "AUROC     |   0.434   |   0.387\n",
      "AUPRC     |   0.968   |   0.949\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 5.006994\n",
      "\tTesting Loss: 7.364989\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 5.048521\n",
      "\tTesting Loss: 7.037988\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.912485\n",
      "\tTesting Loss: 6.839258\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.902729\n",
      "\tTesting Loss: 6.952742\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.891072\n",
      "\tTesting Loss: 7.004515\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.825712\n",
      "\tTesting Loss: 7.235395\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.904755\n",
      "\tTesting Loss: 7.462498\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.902373\n",
      "\tTesting Loss: 7.112637\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.866598\n",
      "\tTesting Loss: 6.856095\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.905762\n",
      "\tTesting Loss: 6.681038\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.645   |   0.624\n",
      "Precision |   0.964   |   0.949\n",
      "Recall    |   0.484   |   0.465\n",
      "AUROC     |   0.480   |   0.452\n",
      "AUPRC     |   0.976   |   0.953\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.958169\n",
      "\tTesting Loss: 6.699793\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.948603\n",
      "\tTesting Loss: 6.901497\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.832660\n",
      "\tTesting Loss: 7.055907\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.885881\n",
      "\tTesting Loss: 7.237628\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.842465\n",
      "\tTesting Loss: 7.525642\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 5.058324\n",
      "\tTesting Loss: 7.149025\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.909024\n",
      "\tTesting Loss: 6.992107\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 5.009856\n",
      "\tTesting Loss: 6.988586\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.884235\n",
      "\tTesting Loss: 7.127084\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.824325\n",
      "\tTesting Loss: 7.123710\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.668   |   0.594\n",
      "Precision |   0.975   |   0.954\n",
      "Recall    |   0.508   |   0.432\n",
      "AUROC     |   0.497   |   0.433\n",
      "AUPRC     |   0.975   |   0.948\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.888343\n",
      "\tTesting Loss: 7.186530\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.899997\n",
      "\tTesting Loss: 7.233641\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.824152\n",
      "\tTesting Loss: 7.064605\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.781343\n",
      "\tTesting Loss: 6.920423\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.919094\n",
      "\tTesting Loss: 6.960654\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.956105\n",
      "\tTesting Loss: 7.200233\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.783584\n",
      "\tTesting Loss: 7.471593\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.793219\n",
      "\tTesting Loss: 7.444768\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.898638\n",
      "\tTesting Loss: 7.330044\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.800063\n",
      "\tTesting Loss: 7.237179\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.677   |   0.608\n",
      "Precision |   0.985   |   0.964\n",
      "Recall    |   0.516   |   0.444\n",
      "AUROC     |   0.549   |   0.502\n",
      "AUPRC     |   0.975   |   0.962\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.819358\n",
      "\tTesting Loss: 6.943787\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.829108\n",
      "\tTesting Loss: 6.848292\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.753004\n",
      "\tTesting Loss: 7.432535\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.808810\n",
      "\tTesting Loss: 7.625175\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.826025\n",
      "\tTesting Loss: 7.545825\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.740214\n",
      "\tTesting Loss: 7.429649\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.755491\n",
      "\tTesting Loss: 7.163149\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.823418\n",
      "\tTesting Loss: 7.113064\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.743358\n",
      "\tTesting Loss: 7.441075\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.730062\n",
      "\tTesting Loss: 7.523468\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.630   |   0.643\n",
      "Precision |   0.983   |   0.951\n",
      "Recall    |   0.464   |   0.485\n",
      "AUROC     |   0.581   |   0.371\n",
      "AUPRC     |   0.982   |   0.933\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.853241\n",
      "\tTesting Loss: 7.562162\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.814596\n",
      "\tTesting Loss: 7.471963\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.703963\n",
      "\tTesting Loss: 7.133763\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.765060\n",
      "\tTesting Loss: 7.281446\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.738827\n",
      "\tTesting Loss: 7.519612\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.681841\n",
      "\tTesting Loss: 7.703187\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.757980\n",
      "\tTesting Loss: 8.050814\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.843442\n",
      "\tTesting Loss: 7.599356\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.706671\n",
      "\tTesting Loss: 7.391442\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.730605\n",
      "\tTesting Loss: 7.384515\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.635   |   0.580\n",
      "Precision |   0.984   |   0.944\n",
      "Recall    |   0.469   |   0.419\n",
      "AUROC     |   0.615   |   0.306\n",
      "AUPRC     |   0.984   |   0.931\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.738531\n",
      "\tTesting Loss: 7.470946\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.701384\n",
      "\tTesting Loss: 7.712550\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.684090\n",
      "\tTesting Loss: 7.753853\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.769121\n",
      "\tTesting Loss: 7.773762\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.665958\n",
      "\tTesting Loss: 8.066678\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.901215\n",
      "\tTesting Loss: 7.786807\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.912735\n",
      "\tTesting Loss: 7.207505\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.848208\n",
      "\tTesting Loss: 7.200438\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.794225\n",
      "\tTesting Loss: 7.566483\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.672899\n",
      "\tTesting Loss: 7.849521\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.641   |   0.670\n",
      "Precision |   0.979   |   0.961\n",
      "Recall    |   0.477   |   0.515\n",
      "AUROC     |   0.532   |   0.599\n",
      "AUPRC     |   0.974   |   0.972\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.709095\n",
      "\tTesting Loss: 7.965947\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.690064\n",
      "\tTesting Loss: 7.801221\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.664888\n",
      "\tTesting Loss: 7.565866\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.610593\n",
      "\tTesting Loss: 7.955697\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.759452\n",
      "\tTesting Loss: 8.061542\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.748818\n",
      "\tTesting Loss: 7.800597\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.571669\n",
      "\tTesting Loss: 7.801212\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.609781\n",
      "\tTesting Loss: 7.886984\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.650891\n",
      "\tTesting Loss: 7.895088\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.634320\n",
      "\tTesting Loss: 7.802763\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.627   |   0.618\n",
      "Precision |   0.978   |   0.941\n",
      "Recall    |   0.461   |   0.461\n",
      "AUROC     |   0.546   |   0.382\n",
      "AUPRC     |   0.970   |   0.954\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.685270\n",
      "\tTesting Loss: 7.636907\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.642976\n",
      "\tTesting Loss: 7.780782\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.570632\n",
      "\tTesting Loss: 8.309090\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.634905\n",
      "\tTesting Loss: 7.961980\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.563287\n",
      "\tTesting Loss: 7.840713\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.577494\n",
      "\tTesting Loss: 7.645585\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.649566\n",
      "\tTesting Loss: 7.889522\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.562371\n",
      "\tTesting Loss: 7.942133\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.557410\n",
      "\tTesting Loss: 8.352930\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.535056\n",
      "\tTesting Loss: 7.988807\n",
      "\tLearning Rate: 0.000081000\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.661   |   0.645\n",
      "Precision |   0.965   |   0.959\n",
      "Recall    |   0.503   |   0.485\n",
      "AUROC     |   0.316   |   0.568\n",
      "AUPRC     |   0.955   |   0.970\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.573603\n",
      "\tTesting Loss: 8.106068\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.588736\n",
      "\tTesting Loss: 8.034853\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.561402\n",
      "\tTesting Loss: 8.245504\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.537507\n",
      "\tTesting Loss: 8.674067\n",
      "\tLearning Rate: 0.000081000\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.607349\n",
      "\tTesting Loss: 8.147238\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.541183\n",
      "\tTesting Loss: 8.026468\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.471875\n",
      "\tTesting Loss: 8.668411\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.664543\n",
      "\tTesting Loss: 8.566336\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.633335\n",
      "\tTesting Loss: 8.272549\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.521632\n",
      "\tTesting Loss: 8.606104\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.588   |   0.665\n",
      "Precision |   0.970   |   0.968\n",
      "Recall    |   0.422   |   0.506\n",
      "AUROC     |   0.487   |   0.459\n",
      "AUPRC     |   0.976   |   0.937\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.632550\n",
      "\tTesting Loss: 8.346352\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.454755\n",
      "\tTesting Loss: 8.783190\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.615389\n",
      "\tTesting Loss: 8.253679\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.617193\n",
      "\tTesting Loss: 7.829134\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.536438\n",
      "\tTesting Loss: 8.249498\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.661523\n",
      "\tTesting Loss: 8.110159\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.595449\n",
      "\tTesting Loss: 8.178030\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.561335\n",
      "\tTesting Loss: 8.642704\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.584363\n",
      "\tTesting Loss: 8.568354\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.550341\n",
      "\tTesting Loss: 8.025389\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.653   |   0.643\n",
      "Precision |   0.969   |   0.951\n",
      "Recall    |   0.492   |   0.485\n",
      "AUROC     |   0.477   |   0.465\n",
      "AUPRC     |   0.972   |   0.958\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.581748\n",
      "\tTesting Loss: 8.001669\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.506570\n",
      "\tTesting Loss: 8.357988\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.512571\n",
      "\tTesting Loss: 8.462297\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.615147\n",
      "\tTesting Loss: 8.619553\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.549601\n",
      "\tTesting Loss: 9.003856\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.741855\n",
      "\tTesting Loss: 8.549656\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.561523\n",
      "\tTesting Loss: 8.063211\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.717262\n",
      "\tTesting Loss: 8.053435\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.726915\n",
      "\tTesting Loss: 8.444040\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.563824\n",
      "\tTesting Loss: 8.697313\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.660   |   0.658\n",
      "Precision |   0.970   |   0.938\n",
      "Recall    |   0.500   |   0.506\n",
      "AUROC     |   0.364   |   0.321\n",
      "AUPRC     |   0.960   |   0.937\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.576786\n",
      "\tTesting Loss: 8.508476\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.513652\n",
      "\tTesting Loss: 8.694324\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.548626\n",
      "\tTesting Loss: 8.800842\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.508348\n",
      "\tTesting Loss: 8.435513\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.454342\n",
      "\tTesting Loss: 8.167804\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.616204\n",
      "\tTesting Loss: 8.237474\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.513781\n",
      "\tTesting Loss: 8.944849\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.604992\n",
      "\tTesting Loss: 9.146545\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.709885\n",
      "\tTesting Loss: 8.608994\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.385390\n",
      "\tTesting Loss: 8.506858\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.671   |   0.690\n",
      "Precision |   0.980   |   0.970\n",
      "Recall    |   0.510   |   0.535\n",
      "AUROC     |   0.569   |   0.556\n",
      "AUPRC     |   0.982   |   0.968\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.370966\n",
      "\tTesting Loss: 9.225215\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.672052\n",
      "\tTesting Loss: 9.044806\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.523406\n",
      "\tTesting Loss: 8.537648\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.540097\n",
      "\tTesting Loss: 8.600588\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.510005\n",
      "\tTesting Loss: 8.931381\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.421628\n",
      "\tTesting Loss: 8.895991\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.394803\n",
      "\tTesting Loss: 8.644857\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.611982\n",
      "\tTesting Loss: 8.608964\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.551771\n",
      "\tTesting Loss: 8.875050\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.403770\n",
      "\tTesting Loss: 8.821127\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.705   |   0.650\n",
      "Precision |   0.968   |   0.967\n",
      "Recall    |   0.555   |   0.490\n",
      "AUROC     |   0.446   |   0.610\n",
      "AUPRC     |   0.965   |   0.967\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.379198\n",
      "\tTesting Loss: 8.469125\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.461255\n",
      "\tTesting Loss: 8.463598\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.368985\n",
      "\tTesting Loss: 9.224698\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.558176\n",
      "\tTesting Loss: 9.128162\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.510702\n",
      "\tTesting Loss: 8.597561\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.409913\n",
      "\tTesting Loss: 8.644970\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.395304\n",
      "\tTesting Loss: 9.161886\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.404618\n",
      "\tTesting Loss: 8.997641\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.346274\n",
      "\tTesting Loss: 8.675488\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.496976\n",
      "\tTesting Loss: 8.578768\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.670   |   0.612\n",
      "Precision |   0.975   |   0.948\n",
      "Recall    |   0.510   |   0.452\n",
      "AUROC     |   0.564   |   0.354\n",
      "AUPRC     |   0.980   |   0.937\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.362679\n",
      "\tTesting Loss: 9.252403\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.534440\n",
      "\tTesting Loss: 9.140206\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.516497\n",
      "\tTesting Loss: 8.565113\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.411434\n",
      "\tTesting Loss: 8.581570\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.415615\n",
      "\tTesting Loss: 9.185923\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.442266\n",
      "\tTesting Loss: 9.260589\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.349439\n",
      "\tTesting Loss: 8.785123\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.492774\n",
      "\tTesting Loss: 8.568521\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.453750\n",
      "\tTesting Loss: 8.852843\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.420409\n",
      "\tTesting Loss: 9.156677\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.671   |   0.639\n",
      "Precision |   0.980   |   0.951\n",
      "Recall    |   0.510   |   0.481\n",
      "AUROC     |   0.613   |   0.432\n",
      "AUPRC     |   0.983   |   0.961\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.412712\n",
      "\tTesting Loss: 9.140547\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.374597\n",
      "\tTesting Loss: 9.054625\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.355592\n",
      "\tTesting Loss: 8.980501\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.341693\n",
      "\tTesting Loss: 8.756088\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.311250\n",
      "\tTesting Loss: 9.257496\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.441370\n",
      "\tTesting Loss: 9.605379\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.401018\n",
      "\tTesting Loss: 9.420530\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.474285\n",
      "\tTesting Loss: 8.847692\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.490629\n",
      "\tTesting Loss: 8.388279\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.503055\n",
      "\tTesting Loss: 8.550047\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.679   |   0.663\n",
      "Precision |   0.985   |   0.946\n",
      "Recall    |   0.518   |   0.510\n",
      "AUROC     |   0.544   |   0.288\n",
      "AUPRC     |   0.974   |   0.930\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.405011\n",
      "\tTesting Loss: 9.231446\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.353285\n",
      "\tTesting Loss: 9.469321\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.345486\n",
      "\tTesting Loss: 8.898306\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.453465\n",
      "\tTesting Loss: 8.748911\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.356105\n",
      "\tTesting Loss: 9.221809\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.419972\n",
      "\tTesting Loss: 9.328549\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.413478\n",
      "\tTesting Loss: 9.122761\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.311461\n",
      "\tTesting Loss: 9.307480\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.326141\n",
      "\tTesting Loss: 9.318441\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.233771\n",
      "\tTesting Loss: 9.012473\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.651   |   0.658\n",
      "Precision |   0.969   |   0.968\n",
      "Recall    |   0.490   |   0.498\n",
      "AUROC     |   0.430   |   0.591\n",
      "AUPRC     |   0.959   |   0.967\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.384027\n",
      "\tTesting Loss: 8.912786\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.296138\n",
      "\tTesting Loss: 9.755199\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.613366\n",
      "\tTesting Loss: 9.886864\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.629577\n",
      "\tTesting Loss: 9.394679\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.331873\n",
      "\tTesting Loss: 9.169214\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.364571\n",
      "\tTesting Loss: 9.212824\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.361362\n",
      "\tTesting Loss: 9.136019\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.334013\n",
      "\tTesting Loss: 9.013206\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.354194\n",
      "\tTesting Loss: 9.174732\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.293962\n",
      "\tTesting Loss: 9.724297\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.675   |   0.679\n",
      "Precision |   0.975   |   0.984\n",
      "Recall    |   0.516   |   0.519\n",
      "AUROC     |   0.515   |   0.695\n",
      "AUPRC     |   0.980   |   0.972\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "\n",
      "Training interrupted by user. Saving current progress...\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.667   |   0.650\n",
      "Precision |   0.980   |   0.952\n",
      "Recall    |   0.505   |   0.494\n",
      "AUROC     |   0.580   |   0.423\n",
      "AUPRC     |   0.971   |   0.949\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.394342\n",
      "\tTesting Loss: 9.479017\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.327817\n",
      "\tTesting Loss: 8.972066\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.411700\n",
      "\tTesting Loss: 8.830290\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.435640\n",
      "\tTesting Loss: 9.122551\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.328907\n",
      "\tTesting Loss: 9.620022\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.328454\n",
      "\tTesting Loss: 9.803990\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.307266\n",
      "\tTesting Loss: 9.426207\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.231219\n",
      "\tTesting Loss: 9.299343\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.208253\n",
      "\tTesting Loss: 9.181861\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.214861\n",
      "\tTesting Loss: 9.722207\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.674   |   0.667\n",
      "Precision |   0.990   |   0.947\n",
      "Recall    |   0.510   |   0.515\n",
      "AUROC     |   0.714   |   0.438\n",
      "AUPRC     |   0.990   |   0.955\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.217640\n",
      "\tTesting Loss: 9.793015\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.220840\n",
      "\tTesting Loss: 9.236395\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.242738\n",
      "\tTesting Loss: 9.178125\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.270721\n",
      "\tTesting Loss: 9.359224\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.168999\n",
      "\tTesting Loss: 10.166359\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.429928\n",
      "\tTesting Loss: 10.275064\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.472315\n",
      "\tTesting Loss: 9.533412\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.171398\n",
      "\tTesting Loss: 9.355789\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.405164\n",
      "\tTesting Loss: 9.250366\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.321746\n",
      "\tTesting Loss: 9.252591\n",
      "\tLearning Rate: 0.000072900\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.689   |   0.599\n",
      "Precision |   0.972   |   0.981\n",
      "Recall    |   0.534   |   0.432\n",
      "AUROC     |   0.453   |   0.657\n",
      "AUPRC     |   0.962   |   0.976\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.314068\n",
      "\tTesting Loss: 9.624695\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.365467\n",
      "\tTesting Loss: 9.583788\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.239576\n",
      "\tTesting Loss: 9.468449\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.353980\n",
      "\tTesting Loss: 9.670673\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.518258\n",
      "\tTesting Loss: 9.575787\n",
      "\tLearning Rate: 0.000072900\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.414904\n",
      "\tTesting Loss: 9.290666\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.208782\n",
      "\tTesting Loss: 9.695581\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "\n",
      "Training interrupted by user. Saving current progress...\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.657   |   0.634\n",
      "Precision |   0.970   |   0.943\n",
      "Recall    |   0.497   |   0.477\n",
      "AUROC     |   0.409   |   0.320\n",
      "AUPRC     |   0.965   |   0.938\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.505076\n",
      "\tTesting Loss: 10.324200\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.859892\n",
      "\tTesting Loss: 10.278769\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.632572\n",
      "\tTesting Loss: 10.037894\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.495727\n",
      "\tTesting Loss: 9.662591\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.393248\n",
      "\tTesting Loss: 9.422258\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.417560\n",
      "\tTesting Loss: 9.444164\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.460370\n",
      "\tTesting Loss: 9.644957\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.399168\n",
      "\tTesting Loss: 10.184423\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.449409\n",
      "\tTesting Loss: 10.000189\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.311213\n",
      "\tTesting Loss: 9.310946\n",
      "\tLearning Rate: 0.000065610\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.629   |   0.674\n",
      "Precision |   0.989   |   0.962\n",
      "Recall    |   0.461   |   0.519\n",
      "AUROC     |   0.606   |   0.488\n",
      "AUPRC     |   0.979   |   0.948\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.332983\n",
      "\tTesting Loss: 9.229893\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.379227\n",
      "\tTesting Loss: 9.366266\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.329060\n",
      "\tTesting Loss: 9.643745\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.292292\n",
      "\tTesting Loss: 9.770383\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.235753\n",
      "\tTesting Loss: 9.911594\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.383939\n",
      "\tTesting Loss: 9.858274\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.358288\n",
      "\tTesting Loss: 9.573923\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.214927\n",
      "\tTesting Loss: 9.809932\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.254168\n",
      "\tTesting Loss: 9.599913\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.227240\n",
      "\tTesting Loss: 9.582781\n",
      "\tLearning Rate: 0.000065610\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.662   |   0.631\n",
      "Precision |   0.980   |   0.966\n",
      "Recall    |   0.500   |   0.469\n",
      "AUROC     |   0.597   |   0.478\n",
      "AUPRC     |   0.981   |   0.951\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.432165\n",
      "\tTesting Loss: 9.582273\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.420070\n",
      "\tTesting Loss: 9.958479\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.172211\n",
      "\tTesting Loss: 10.119453\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.400669\n",
      "\tTesting Loss: 10.043797\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.559500\n",
      "\tTesting Loss: 9.633761\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.312545\n",
      "\tTesting Loss: 9.709841\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.375978\n",
      "\tTesting Loss: 10.031430\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.549941\n",
      "\tTesting Loss: 10.042900\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.293852\n",
      "\tTesting Loss: 10.196739\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.364539\n",
      "\tTesting Loss: 10.290167\n",
      "\tLearning Rate: 0.000065610\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.659   |   0.681\n",
      "Precision |   0.965   |   0.962\n",
      "Recall    |   0.500   |   0.527\n",
      "AUROC     |   0.316   |   0.505\n",
      "AUPRC     |   0.945   |   0.962\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.477971\n",
      "\tTesting Loss: 9.984592\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.293842\n",
      "\tTesting Loss: 9.668295\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.259494\n",
      "\tTesting Loss: 9.542372\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.370574\n",
      "\tTesting Loss: 9.560562\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.266214\n",
      "\tTesting Loss: 10.005007\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.208711\n",
      "\tTesting Loss: 10.106893\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [7/10]\n",
      "\tTraining Loss: 4.247066\n",
      "\tTesting Loss: 9.612619\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [8/10]\n",
      "\tTraining Loss: 4.114629\n",
      "\tTesting Loss: 9.956908\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [9/10]\n",
      "\tTraining Loss: 4.204440\n",
      "\tTesting Loss: 10.114338\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [10/10]\n",
      "\tTraining Loss: 4.207931\n",
      "\tTesting Loss: 10.160743\n",
      "\tLearning Rate: 0.000065610\n",
      "----------------------------------------------------------------------\n",
      "Metric     |  Training  |  Testing\n",
      "----------------------------------------------------------------------\n",
      "F1        |   0.643   |   0.659\n",
      "Precision |   0.979   |   0.960\n",
      "Recall    |   0.479   |   0.502\n",
      "AUROC     |   0.584   |   0.552\n",
      "AUPRC     |   0.977   |   0.973\n",
      "----------------------------------------------------------------------\n",
      "beta: 1.0\n",
      "Epoch [1/10]\n",
      "\tTraining Loss: 4.290879\n",
      "\tTesting Loss: 10.110303\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [2/10]\n",
      "\tTraining Loss: 4.262595\n",
      "\tTesting Loss: 9.926268\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [3/10]\n",
      "\tTraining Loss: 4.147095\n",
      "\tTesting Loss: 9.691513\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [4/10]\n",
      "\tTraining Loss: 4.221636\n",
      "\tTesting Loss: 9.756832\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [5/10]\n",
      "\tTraining Loss: 4.210832\n",
      "\tTesting Loss: 10.061655\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n",
      "Epoch [6/10]\n",
      "\tTraining Loss: 4.108986\n",
      "\tTesting Loss: 10.181066\n",
      "\tLearning Rate: 0.000065610\n",
      "beta: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):  # n_evals\n",
    "    train_losses_tmp, test_losses_tmp = train_vital(model, \n",
    "                                                    train_dataloader,\n",
    "                                                    test_dataloader, \n",
    "                                                    optimizer, \n",
    "                                                    scheduler,\n",
    "                                                    kl_annealer,\n",
    "                                                    num_epochs=10, \n",
    "                                                    train_type='clip')\n",
    "    train_losses = train_losses + train_losses_tmp\n",
    "    test_losses = test_losses + test_losses_tmp\n",
    "    # every num_epochs, evaluate the model\n",
    "    model.eval()\n",
    "    if config_dict['3d']:\n",
    "        train_eval_metrics = eval_clip3d(model, evalinputs_train)\n",
    "        test_eval_metrics = eval_clip3d(model, evalinputs_test)\n",
    "    else:\n",
    "        train_eval_metrics = eval_clip(model, evalinputs_train)\n",
    "        test_eval_metrics = eval_clip(model, evalinputs_test)\n",
    "    train_eval_metrics_list.append(train_eval_metrics)\n",
    "    test_eval_metrics_list.append(test_eval_metrics)\n",
    "    eval_dict= {'train_losses': train_losses,\n",
    "                'test_losses': test_losses,\n",
    "                'train_evals': train_eval_metrics_list,\n",
    "                'test_evals': test_eval_metrics_list }\n",
    "    eval_dict_eng = eng_eval_metrics(eval_dict, binary=True, plot=False)\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"Metric     |  Training  |  Testing\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"F1        |   {eval_dict_eng['train_f1'][-1]:.3f}   |   {eval_dict_eng['test_f1'][-1]:.3f}\")\n",
    "    print(f\"Precision |   {eval_dict_eng['train_precision'][-1]:.3f}   |   {eval_dict_eng['test_precision'][-1]:.3f}\")\n",
    "    print(f\"Recall    |   {eval_dict_eng['train_recall'][-1]:.3f}   |   {eval_dict_eng['test_recall'][-1]:.3f}\")\n",
    "    print(f\"AUROC     |   {eval_dict_eng['train_auroc'][-1]:.3f}   |   {eval_dict_eng['test_auroc'][-1]:.3f}\")\n",
    "    print(f\"AUPRC     |   {eval_dict_eng['train_auprc'][-1]:.3f}   |   {eval_dict_eng['test_auprc'][-1]:.3f}\")\n",
    "    print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change attention to 256\n",
    "# init_lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<eval.EvalInputs object at 0x1066489d0>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalinputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
